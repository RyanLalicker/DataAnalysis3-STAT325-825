---
title: "Data Analysis 3"
authors: 
  Maksuda Aktar Toma,
  Jo Charbonneau,
  Ryan Lalicker
date: today
date-format: long
execute: 
  echo: false
  warning: false
columns: 2
format:
  pdf: 
    fig-align: center
    fig-width: 6
    fig-height: 4
bibliography: references.bib
editor: 
  markdown: 
    wrap: sentence
---

```{r, , fig.pos="H"}
#| label: data-setup
#| echo: false
#| eval: true

library(knitr)
library(dplyr)
library(ggplot2)
library(naniar)
library(reshape2)
library(GGally)
library(janitor)
library(emmeans)
library(MASS)
library(multcomp)
library(lme4)
library(nnet)

data <- read.csv("data.csv")
# Placeholder of original data
origdata <- data
data <- data %>%
  mutate(across(everything(), ~ ifelse(. %in% c(".", ""), NA, .)))


```

```{r, , fig.pos="H"}
#| label: Scratch-work
#| echo: false
#| eval: false

length(unique(na.omit(data$Sire)))
length(unique(na.omit(data$Development.Treatment)))
sum(rowSums(is.na(data)) > 0)
rows_with_na <- sum(rowSums(is.na(data)) > 0)
unique_entries <- unique(data$Calan.Treatment)
num_unique <- length(unique_entries)
frequency_table <- table(data$Calan.Treatment)
```


# Introduction

In this paper we will be looking at data related to calves.  The data comes from an experiment designed to study the impact dietary treatments given to pregnant heifers had on the development of the calves.  The study was conducted over a three year period and involved three different dietary treatments given to select groups of heifers in the final trimester.  In total the data has 22 variables for 120 entries, though some data points are missing.

For more information on the experiment, the data, or any other files used in this paper see our [Github page](https://github.com/RyanLalicker/Data-Analysis-2-STAT-325-825) which can be found at https://github.com/RyanLalicker/Data-Analysis-2-STAT-325-825.  The coding languages used in the paper are R and SAS.  The corresponding code can be found in *Appendix A - R Code* and *Appendix B - SAS Code* respectively.


# Exploring the Data

## Variables

As mentioned above the experiment used three different dietary treatments.  These were DDG, CON, and MET.  For the first two trimesters the heifers were given one of seven developmental treatments, found in `Development.Treatment`, and then in the final trimester the each was given one of the three treatments mentioned above.  This is recorded in the `Calan.Treatment` column of the dataset.  

The heifers were placed into one of four pens by weight, which can be seen in the column `Pen #`.  They were then artificially inseminated from an assigned sire, which we will assume was done randomly since the client says weight was not a factor.  The sire is represented by the column of the same name and has six unique entries.

Upon the birth of the calves, several measurements were taken.  These include the sex of the calf, weights taken at both birth and slaughter, and scores of both the calf's vigor and the ease of birth.  The variable names line up with these descriptions.

Other variables, such as the id of the calf, length of gestation for the heifer, and postmortem scoring such as hot carcass weight (HCW) are included as well.  (@UNLBeef).  Note two birthdays are included in the data, `Birth.date` and `Birth.date.1`.  These variables will not be used in the models below so no further investigation was done on our part to determine the differences.  

The client's main focus is the effect the third trimester treatment and the sex of a calf have on the calf's vigor score, ease of birth score, and final body weight.  Therefore, these are the variables we will place more of an emphasis on, while exploring the effect some of the other variables may have.


## Missing Values

The data contains some missing values. In total 53 rows in the dataset are missing at lease one variable. @fig-missing-data shows which columns have the most missing data.  As we can see the values for the variable `DMI`, which according to the USDA represents the dry matter intake for a cow, is missing for two-thirds of the entries. (@USDA). Given the number of missing values is this large, it is probably best to not use this variable in our models.  Some other variables, including the final body weight of the calf represented by `Final.Calf.BW`, are missing in 19 entries.  Of the other four variables the client was most interested in, none have more than ten missing values.    

```{r, , fig.pos="H"}
#| label: fig-missing-data
#| fig-cap: "Chart counting the number of missing values for each variable within the data."
#| echo: false
#| eval: true

gg_miss_var(data) +
  ggtitle("Missing Data Distribution") +
  theme_minimal()

```


## Cleaning the Dataset

```{r,,fig.pos="H"}
#| label: cleaning
#| echo: false
#| eval: true

var_used <- c("Calan.Treatment", "SEX", "Calving.Ease", "Calf.Vigor", "Final.Calf.BW", "Pen..", "Initial.BW", "Sire")
cleaned_data <- data[complete.cases(data[, var_used]), ]

```

Due to the missing values discussed above, we need to clean this dataset before continuing.  There are generally two ways to handle missing values.  The first is imputing them with some metric like the mean, median, or mode of the variable.  The second is to just remove any rows with missing data.

We decided to cut all rows that contained missing values for variables we are interested in.  These variables include the five variables the client is interested in, but also the pen number, sire, and the initial weight of the mother.  The latter two are `Sire` and `Initial.BW` in the dataset.  After removing missing values for these entries the dataset has 101 rows, which we feel is an ample amount for analyzing the data.  Note all future figures and models come from this cleaned dataset and not the original.

We initially considered imputing the quantitative variables with the respective median values and using the mode for categorical variables as @MEMON2023101382 suggests.  This has some issues though.  For an example let's consider the third trimester treatment.  The MET treatment was used in 40 cases, while the other two treatments were only used 38 times, meaning there are four missing values.  If we mode impute this variable there will be 42 instances of the MET treatment.  However, it seems very possible that the missing entries were split between the CON and DDG treatments to make an even 40 uses each.  While imputing quantitative variables is less risky, we are not fully comfortable with that approach either since we are trying to analyze the data.


## Summary Statistics

Let's take a closer look at what the three dependent variables the client is interested in.  @fig-summary-stats shows several summary statistics for each.  The calving ease and calf vigor are each scores given.  Looking at the minimum and maximum values of each it would seem they are scored in a three-point and five-point system respectively, both only using integers.  We can also see from the median and 75th percentiles that both seem very skewed towards the low end of the scale.  While the imputing done previously may be exaggerating the curve, @fig-missing-data shows less than ten values were imputed.  This indicates to us the skew was already present before cleaning the data.


```{r, , fig.pos="H"}
#| label: fig-summary-stats
#| echo: false
#| eval: true

dep_vars <- c("Calving.Ease", "Calf.Vigor", "Final.Calf.BW")

custom_names <- c("Calving Ease", "Calf Vigor", "Final Calf Weight")

cleaned_data$Calving.Ease <- as.numeric(cleaned_data$Calving.Ease)
cleaned_data$Calf.Vigor <- as.numeric(cleaned_data$Calf.Vigor)
cleaned_data$Final.Calf.BW <- as.numeric(cleaned_data$Final.Calf.BW)

calc_stats <- function(var) {
  mean_val <- mean(var, na.rm = TRUE)
  median_val <- median(var, na.rm = TRUE)
  sd_val <- sd(var, na.rm = TRUE)
  quantiles <- quantile(var, probs = c(0.25, 0.75), na.rm = TRUE)
  max <- max(var, na.rm = TRUE)
  min <- min(var, na.rm = TRUE)
  c(mean = mean_val, median = median_val, sd = sd_val, Q1 = quantiles[1], Q3 = quantiles[2], Min = min, Max = max)
}

summary_table <- t(sapply(dep_vars, function(var) calc_stats(cleaned_data[[var]])))

summary_table <- as.data.frame(summary_table)

kable(summary_table, col.names = c("Variable", "Mean", "Median", "SD", "25th Percentile", "75th Percentile", "Min", "Max"), 
      caption = "Summary Statistics for Dependent Variables")

```

The final weight of calf is the third variable in @fig-summary-stats.  The mean and median are relatively similar given the large standard deviation.  Going forward we can treat these variables as ordinal, which is just a cateogrical variable with an order.

While the previous two variables discussed had some concerns on top of being counting variables on a scale, the final weight does not present the same issues.  Further investigation into the approximate distribution of the final weight is needed though.

Let's look at a histogram and a Q-Q plot for the final weight of the calves in @fig-normality.  The bin width for the histogram comes from the Freedman-Diaconis rule.  (@Freedman).  The histogram appears to follow an approximately normal distribution.  The Q-Q plot mostly follows this as most points follow the linear trend represented by the red line.

```{r, , fig.pos="H"}
#| label: fig-normality
#| echo: false
#| eval: true
#| fig-cap: "Plots used to check if the distribution of the final calf weight is normal."
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Histogram of final calf weight."
#|  - "Q-Q plot of final calf weight."
#| fig-width: 6
#| fig-height: 4

bin_width <- round(2*IQR(cleaned_data$Final.Calf.BW)/(length(cleaned_data$Final.Calf.BW))^(1/3), 2)

ggplot(cleaned_data, aes(x = Final.Calf.BW)) +
  geom_histogram(binwidth = bin_width, color = "black", fill = "skyblue") +
  labs(
    x = "Weight",
    y = "Frequency"
  ) +
  theme_minimal()

ggplot(cleaned_data, aes(sample = Final.Calf.BW)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal()


```

Before moving on we want to look at plots of the scoring variables as well.  While we suspect a heavy skew for each, the histograms in @fig-scoring-dist verify this.  It is important to remember that these two variables are not continuous like the weight variable, so the types of models used will vary.

```{r, , fig.pos="H"}
#| label: fig-scoring-dist
#| echo: false
#| eval: true
#| fig-cap: "Histograms of scoring variables."
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Histogram of calving ease."
#|  - "Histogram of calf vigor."
#| fig-width: 6
#| fig-height: 4


ggplot(cleaned_data, aes(x = Calving.Ease)) +
  geom_histogram(binwidth = 1, color = "black", fill = "skyblue") +
  labs(
    x = "Ease Score",
    y = "Frequency"
  ) +
  theme_minimal()

ggplot(cleaned_data, aes(x = Calf.Vigor)) +
  geom_histogram(binwidth = 1, color = "black", fill = "skyblue") +
  labs(
    x = "Vigor Score",
    y = "Frequency"
  ) +
  theme_minimal()

```



## Exploring the Data

Before looking at potential models, let's explore how some of the variables interact with each other.  While we will be able to include other explanatory variables, the client specifically mentions using the third trimester treatment and the sex of a calf as explanatory variables of interest.  The table in @fig-table shows the breakdown of treatment by sex.  Note HFR stands for heifer and STR stands for steer.  Although not every group has an equivalent number of subjects, this is nothing we are concerned about.  Please note that the total occurrences per treatment are different than discussed above since rows containing missing values were removed.

```{r, , fig.pos="H"}
#| label: fig-table
#| echo: false
#| eval: true
#| fig-cap: "Table showing the breakdown of treatment by sex."


data2 <- cleaned_data

crosstab_treatment_sex <- table(data2$Calan.Treatment, data2$SEX)

kable(
  crosstab_treatment_sex)


```



One of the key assumptions for some of the models we will be discussing later is that the explanatory variables of the model are not highly correlated with each other.  If this assumption is violated, multicollinearity is present.  Since both the treatment and the sex of the calf are categorical, we can use the Pearson's chi-squared on the table in @fig-table to determine if multicollinearity is a problem for these variables.  (@ChiSquared).  The results of the test, shown in @fig-chi, indicate multicollinearity is not a problem since the p-value is well above any commonly used significance level such as 0.05.


```{r, , fig.pos="H"}
#| label: fig-chi
#| echo: false
#| eval: true
#| fig-cap: "Chi-squared test for treatment and sex."


chi_sq_test <- chisq.test(crosstab_treatment_sex)
chi_sq_table <- data.frame(
  Metric = c("Statistic", "Degrees of Freedom", "P-Value"),
  Value = c(round(chi_sq_test$statistic, 2), 
            chi_sq_test$parameter, 
            format.pval(chi_sq_test$p.value)),
  stringsAsFactors = FALSE
)

kable(chi_sq_table, align = c("l", "c"), row.names = FALSE)

```

Now let's consider how these variables affect the final body weight. The boxplot shown in @fig-box-1 allows us to see this relationship graphically.  We can see the steers are heavier on average than the heifers.  The treatments seem to different variances as well, but their median values are not different by huge quantities.  Both the CON and MET treatments had one steer large enough to be an outlier, while the DDG treatment had several outliers for both sexes.


```{r, , fig.pos="H"}
#| label: fig-box-1
#| echo: false
#| eval: true
#| fig-cap: "Final body weight by treatment and sex."
#| fig-width: 6
#| fig-height: 4

ggplot(data2, aes(x = Calan.Treatment, y = Final.Calf.BW, fill = SEX)) +
  geom_boxplot(outlier.color = "red", alpha = 0.7) +
  labs(x = "Treatment", y = "Final Body Weight") +
  theme_minimal()

```

Another variable we want to investigate graphically is the initial weight of the heifer that birthed the calf.  Let's see how it compares to both the ease and vigor score.  In @fig-bodyweight-scatter we can see this while also accounting for both the third trimester treatment with the shape of the data point and the sex of the calf with the color of the data point.  This allows us to see both how the effect the heifer's initial weight has, but also the trends of both treatment and sex.

```{r, , fig.pos="H"}
#| label: fig-bodyweight-scatter
#| echo: false
#| eval: true
#| fig-cap: "Scatterplot of heifer's initial body weight versus scoring variables, controlling for third trimester treatment and sex of the calf."
#| fig-width: 6
#| fig-height: 4
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Initial body weight vs. calf vigor."
#|  - "Initial body weight vs. calving ease."

data2$Initial.BW <- as.numeric(data2$Initial.BW)

ggplot(data2, aes(x = Calf.Vigor, y = Initial.BW, color = SEX, shape = Calan.Treatment)) +
  geom_point(size = 3, alpha = 0.7) +
  labs(x = "Calf Vigor", y = "Initial Body Weight of Heifer") +
  theme_minimal()

ggplot(data2, aes(x = Calving.Ease, y = Initial.BW, color = SEX, shape = Calan.Treatment)) +
  geom_point(size = 3, alpha = 0.7) +
  labs(x = "Calving Ease", y = "Initial Body Weight of Heifer") +
  theme_minimal()

```
**Summarize and consider more plots**

# Models for Calving Ease

Since the client is interested in three different dependent variables we will need to handle one variable at a time.  For the next two models we will be focused on calving ease.

## Ordinal Logistic Regression Model

Since calving ease is a score from one to three it can be considered an ordinal variable.  This means instead of treating it as a quantitative variable as we did previously, it could be considered an ordered categorical variable.  One method of modeling ordinal variables is with ordinal logistic regression, or OLS.  This uses one or more independent variables to predict the ordinal value of the dependent variable.  A key assumption of OLS, outside of the dependent variable being ordinal, is no multicollinearity between independent variables.  (@StAndrews).

Let's attempt to apply an OLS to the calving ease variable.  In this simple case we will use the third trimester treatment and the calf's sex as the independent variables. As we saw in @fig-chi, multicollinearity is not a problem with these variables, so we may procede.

**START BACK HERE**

```{r, , fig.pos="H"}
#| label: fig-OLS-Ease
#| echo: false
#| eval: true

data2$Calving.Ease <- factor(data2$Calving.Ease, ordered = TRUE)

ease_model_3 <- polr(Calving.Ease ~ Calan.Treatment * SEX, data = data2, Hess = TRUE)

summary(ease_model_3)

# Extract p-values
coefs <- coef(summary(ease_model_3))
p_values <- pnorm(abs(coefs[, "t value"]), lower.tail = FALSE) * 2  # Two-tailed p-values
coefs <- cbind(coefs, "p-value" = p_values)
print(coefs)

```

## CUT THIS - Multinomial Logistic Regression

```{r, , fig.pos="H"}
#| label: fig-MVR-Ease
#| echo: false
#| eval: true

ease_model_4 <- multinom(Calving.Ease ~ Calan.Treatment * SEX, data = data2)
summary(ease_model_4)

```
**Pairwise Comparisons**
```{r, , fig.pos="H"}
#| label: fig-MVR-Ease-Comparisons
#| echo: false
#| eval: true

emm_ease <- emmeans(ease_model_4, ~ Calan.Treatment | SEX)
pairs(emm_ease)

```

# Models for Calf Vigor

## Ordinal Logistic Regression Model

```{r, , fig.pos="H"}
#| label: fig-OLS-Vigor
#| echo: false
#| eval: true

data2$Calf.Vigor <- factor(data2$Calf.Vigor, ordered = TRUE)

vigor_model_1 <- polr(Calf.Vigor ~ Calan.Treatment * SEX, data = data2, Hess = TRUE)

summary(vigor_model_1)

# Extract p-values
coefs <- coef(summary(vigor_model_1))
p_values <- pnorm(abs(coefs[, "t value"]), lower.tail = FALSE) * 2  # Two-tailed p-values
coefs <- cbind(coefs, "p-value" = p_values)
print(coefs)

```


**Pairwise comparisons**
```{r, , fig.pos="H"}
#| label: fig-OLS-Vigor-Comp
#| echo: false
#| eval: true

emm_vigor <- emmeans(vigor_model_1, ~ Calan.Treatment | SEX)
pairs(emm_vigor)

```

## CUT THIS - Multinomial Logistic Regression

```{r, , fig.pos="H"}
#| label: fig-MVR-Vigor
#| echo: false
#| eval: true

vigor_model_2 <- multinom(Calf.Vigor ~ Calan.Treatment * SEX, data = data2)
summary(vigor_model_2)

```



# Models for Final Calf Weight

## Linear Model

```{r, , fig.pos="H"}
#| label: fig-LM
#| echo: false
#| eval: true
#| layout-ncol: 2
#| layout-nrow: 2

data2$Calan.Treatment <- as.factor(data2$Calan.Treatment)

weight_model_5 <- lm(Final.Calf.BW ~ Calan.Treatment * SEX, data = data2)
summary(weight_model_5)

```

**Tukey comparison**
```{r, , fig.pos="H"}
#| label: fig-LM-Comparison
#| echo: false
#| eval: true

tukey_weight <- glht(weight_model_5, linfct = mcp(Calan.Treatment = "Tukey"))

summary(tukey_weight)

```

## Linear Mixed Model

**This will need to be redone in SAS if we stick with it.**
```{r, , fig.pos="H"}
#| label: fig-LMM
#| echo: false
#| eval: true

weight_model_6 <- lmer(Final.Calf.BW ~ Calan.Treatment * SEX + (1|Pen..) + (1|Sire), data = data2)
summary(weight_model_6)

```

**Tukey comparison**
```{r, , fig.pos="H"}
#| label: fig-LMM-Tukey-Comparison
#| echo: false
#| eval: true

tukey_weight1 <- glht(weight_model_6, linfct = mcp(Calan.Treatment = "Tukey"))

summary(tukey_weight1)

```

**Pariwise comparison**
```{r, , fig.pos="H"}
#| label: fig-LMM-Pairwise-Comparison
#| echo: false
#| eval: true

emm_weight <- emmeans(weight_model_6, ~ Calan.Treatment | SEX)
pairs(emm_weight)

```

## ANCOVA Model

This includes initial weight.

```{r, , fig.pos="H"}
#| label: fig-ANCOVA
#| echo: false
#| eval: true

ancova_model <- lm(Final.Calf.BW ~ Calan.Treatment * SEX + Initial.BW, data = data2)

summary(ancova_model)

```

```{r, , fig.pos="H"}
#| label: fig-ANCOVA-assumptions
#| echo: false
#| eval: true
#| fig-cap: ""
#| layout-ncol: 2
#| latout-nrow: 2
#| fig-subcap: 
#|  - ""
#|  - ""
#|  - ""
#|  - ""
#| fig-width: 6
#| fig-height: 4

#par(mfrow = c(2, 2))
plot(ancova_model)

```

**Post Hoc Test**
```{r, , fig.pos="H"}
#| label: fig-ANCOVA-Post-HOC
#| echo: false
#| eval: true

emm <- emmeans(ancova_model, ~ Calan.Treatment | SEX)
pairs(emm)

```

## Binary Logistic Regression with GLM

```{r, , fig.pos="H"}
#| label: fig-Binary-log-reg-GLM
#| echo: false
#| eval: true

# Dichotomize Calf Vigor (example: low = 1, 2; high = 3, 4, 5)
data$Calf.Vigor.Binary <- ifelse(data$Calf.Vigor %in% c(1, 2), "Low", "High")
data$Calf.Vigor.Binary <- factor(data$Calf.Vigor.Binary, levels = c("Low", "High"))

# Fit binary logistic regression
vigor_model_glm <- glm(Calf.Vigor.Binary ~ Calan.Treatment * SEX + Initial.BW, 
                       data = data, 
                       family = binomial(link = "logit"))

# Summarize the model
summary(vigor_model_glm)

```


$$
y_{ijklmn} = ENTER-MODEL-HERE
$$

where $y_{ijklm}$ represents the *dependent variable*, ...

```![Picture of SAS Output](filename.png){width="3in"}```



# Conclusion

# Recomendation

\newpage

# References

::: {#refs}
:::

\newpage

# Appendix A - R Code

```{r, , fig.pos="H"}
#| label: appendix A
#| echo: true
#| eval: false

```

\newpage

# Appendix B - SAS Code

``` sas

```

\newpage

# Appendix C - Additional SAS Output



```![](filename.png)```
