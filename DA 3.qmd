---
title: "Data Analysis 3"
authors: 
  Maksuda Aktar Toma,
  Jo Charbonneau,
  Ryan Lalicker
date: today
date-format: long
execute: 
  echo: false
  warning: false
columns: 2
format:
  pdf: 
    extensions-dir: quarto-wordcount/_extensions/wordcount
    fig-align: center
    fig-width: 6
    fig-height: 4
bibliography: references.bib
editor: 
  markdown: 
    wrap: sentence
---

# Introduction

In this paper we will be looking at data related to calves.  The data comes from an experiment designed to study the impact dietary treatments given to pregnant heifers had on the development of the calves.  The study was conducted over a three year period and involved three different dietary treatments given to select groups of heifers in the final trimester.  In total the data has 22 variables for 120 entires, though some data points are missing.

For more information on the experiment, the data, or any other files used in this paper see our [Github page](https://github.com/RyanLalicker/Data-Analysis-2-STAT-325-825) which can be found at https://github.com/RyanLalicker/Data-Analysis-2-STAT-325-825.  The coding languages used in the paper are R and SAS.  The corresponding code can be found in *Appendix A - R Code* and *Appendix B - SAS Code* respectively.



# Exploring the Data

## Variables

As mentioned above the experiment used three different dietary treatments.  These were DDG, CON, and MET.  For the first two trimesters the heifers were given one of seven developmental treatments, found in `Development.Treatment`, and then in the final trimester the each was given one of the three treatments mentioned above.  This is recorded in the `Calan.Treatment` column of the data set.  

The heifers were placed into one of four pens by weight, which can be seen in the column `Pen #`.  They were then artificially inseminated from an assigned sire, which we will assume was done randomly since the client says weight was not a factor.  The sire is represented by the column of the same name and has six unique entries.

Upon the birth of the calves, several measurements were taken.  These include the sex of the calf, weights taken at both birth and slaughter, and scores of both the calf's vigor and the ease of birth.  The variable names line up with these descriptions.

Other variables, such as the id of the calf, length of gestation for the heifer, and postmortem scoring such as hot carcass weight (HCW) are included as well.  (@UNLBeef).  Note two birthdays are included in the data, `Birth.date` and `Birth.date.1`.  These variables will not be used in the models below so no further investigation was done on our part to determine the differences.  

The client's main focus is the effect the third trimester treatment and the sex of a calf have on the calf's vigor score, ease of birth score, and final body weight.  Therefore, these are the variables we will place more of an emphasis on, while exploring the effect some of the other variables may have.


```{r, , fig.pos="H"}
#| label: data-setup
#| echo: false
#| eval: true

library(knitr)
library(dplyr)
library(ggplot2)
data <- read.csv("data.csv")
origdata <- data
data <- data %>%
  mutate(across(everything(), ~ ifelse(. %in% c(".", ""), NA, .)))
# May need to add more later.
neededvars <- c("Calan.Treatment", "SEX", "Final.Calf.BW", "Calving.Ease", "Calf.Vigor")
data <- data[complete.cases(data[, neededvars]), ]
```

```{r, , fig.pos="H"}
#| label: Scratch-work
#| echo: false
#| eval: false



length(unique(na.omit(data$Sire)))
length(unique(na.omit(data$Development.Treatment)))
sum(rowSums(is.na(data)) > 0)

```


```{r, , fig.pos="H"}
#| label: data-setup
#| echo: false
#| eval: true

library(knitr)
library(dplyr)
library(ggplot2)
setwd("C:/Users/mtoma2/Documents/Fall 24/Stat 825/Data Analysis/DataAnalysis3-STAT325-825")
data <- read.csv("data.csv")

```

## Misiing Value
Initially the dataset has missing values in the following columns:
Pen #: 4 missing values
DMI: 36 missing values
SEX: 1 missing value

The heatmap above visualizes the distribution of missing data in the dataset. Columns with missing values (e.g., "Pen #", "DMI", and "SEX") are marked with red line gaps.
```{r, , fig.pos="H"}
#| label: Scratch work
#| echo: false
#| eval: false

# Load necessary libraries
library(ggplot2)
library(naniar)

# Assuming your dataset is named `data`
# Visualize missing data distribution
gg_miss_var(data) +
  ggtitle("Missing Data Distribution") +
  theme_minimal()

#2. Heatmap
# Load necessary libraries
library(ggplot2)
library(reshape2)

# Assuming your dataset is named `data`
# Create a binary matrix indicating missing values
missing_matrix <- is.na(data)

# Convert the missing matrix to a long format for visualization
missing_data_long <- melt(missing_matrix)
colnames(missing_data_long) <- c("Row", "Column", "Missing")

# Create the heatmap
ggplot(missing_data_long, aes(x = Column, y = Row, fill = Missing)) +
  geom_tile(color = "white") +
  scale_fill_manual(values = c("FALSE" = "grey", "TRUE" = "red"), 
                    name = "Missing") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Missing Data Heatmap")


```

# Cleaning the dataset
This code cleans a dataset by replacing all occurrences of . with NA to standardize missing values. It ensures columns are assigned the correct data types, converting numeric-like columns to numeric and others to factor. Missing values are handled by imputing the median for numeric columns and the mode for factor columns. After cleaning, the code verifies that no missing values remain in the dataset.
```{r}
# Load dplyr for data manipulation
library(dplyr)

# Step 1: Replace all "." with NA in the dataset
data_cleaned <- data  # Assuming `data` is your original dataset
data_cleaned[data_cleaned == "."] <- NA

# Step 2: Convert columns to appropriate types (numeric or factor)
data_cleaned <- data_cleaned %>%
  mutate(across(everything(), ~ if (all(!is.na(.x) & grepl("^[0-9.]+$", .x))) {
                                      as.numeric(.x)
                                    } else {
                                      as.factor(.x)
                                    }))

# Step 3: Impute missing values
# Define a function to calculate the mode
get_mode <- function(x) {
  unique_x <- unique(na.omit(x))
  unique_x[which.max(tabulate(match(x, unique_x)))]
}

# Impute missing values
data_cleaned <- data_cleaned %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
  mutate(across(where(is.factor), ~ ifelse(is.na(.), get_mode(.), .)))

# Step 4: Verify if there are any remaining missing values
missing_values_after_cleaning <- sum(is.na(data_cleaned))
print(paste("Remaining missing values: ", missing_values_after_cleaning))

# Step 5: Save the cleaned dataset to a CSV file
write.csv(data_cleaned, "cleaned_data.csv", row.names = FALSE)

View(data_cleaned)
# Save to the Desktop (modify based on your system)
write.csv(data_cleaned, "C:/Users/mtoma2/Desktop/cleaned_data.csv", row.names = FALSE)


```


## Summary Statistics
```{r}
library(GGally)
# Summary statistics for numerical variables
summary_stats_num <- cleaned_data %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd, min = min, max = max, median = median), na.rm = TRUE))

# Summary statistics for categorical variables
summary_stats_cat <- cleaned_data %>%
  summarise(across(where(is.factor), ~ n_distinct(.)))

print("Summary Statistics for Numerical Variables")
print(summary_stats_num)
print("Summary Statistics for Categorical Variables")
print(summary_stats_cat)

```


# Exploring the Data

```{r, , fig.pos="H"}
#| label: Scratch work
#| echo: false
#| eval: false

library(janitor)

# Clean column names
cleaned_data <- cleaned_data %>% clean_names()


# Select numerical variables
numeric_vars <- cleaned_data %>% select(where(is.numeric))

# Plot histograms for all numerical variables
for (col in colnames(numeric_vars)) {
  p <- ggplot(cleaned_data, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
    labs(title = paste("Distribution of", col), x = col, y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
  
  # Explicitly print the plot
  print(p)
}


```


## Variables

Columns in data set can be typed like `column`.

### POTENTIAL Changes made to the variables in the original data set




```{r, , fig.pos="H"}
#| label: fig-summarystats
#| echo: false
#| eval: true


```


```{r, , fig.pos="H"}
#| label: fig-normallity
#| echo: false
#| eval: true
#| layout-ncol: 2
#| fig-cap: ""
#| fig-subcap: 
#|  - ""
#|  - ""
#| fig-width: 6
#| fig-height: 4

```

## Relationships among variables

# Potential models
```{r}
# Ensure calan_treatment and sex are factors
cleaned_data$calan_treatment <- as.factor(cleaned_data$calan_treatment)
cleaned_data$sex <- as.factor(cleaned_data$sex)
# ANCOVA for Final Body Weight
model <- aov(`final_calf_bw` ~ `calan_treatment` * sex + `initial_bw`, data = cleaned_data)
summary(model)

# Tukey's HSD for factors only
TukeyHSD(model, which = c("calan_treatment", "sex"))



```


```{r}
# ANCOVA for Final Body Weight
model <- aov(`Final Calf BW` ~ `Calan Treatment` * SEX + `Initial BW`, data = imputed_data)
summary(model)

```


## Model 1



$$
y_{ijklmn} = ENTER-MODEL-HERE
$$

where $y_{ijklm}$ represents the *dependent variable*, ...

![Picture of SAS Output](filename.png){width="3in"}

# Conclusion

# Recomendation

\newpage

# References

::: {#refs}
:::

\newpage

# Appendix A - R Code

```{r, , fig.pos="H"}
#| label: appendix A
#| echo: true
#| eval: false

```

\newpage

# Appendix B - SAS Code

``` sas

```

\newpage

# Appendix C - Additional SAS Output



![](filename.png)
